{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23338d76-e201-40f0-b91f-0790ecf9dbca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SageMaker Inference Recommender for Real-Time Endpoints & Benchmark tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8bf58-10e0-4cce-93a6-d693fd596e18",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this notebook we will demonstrate how you can use SageMaker Inference Recommender & benchmark test for your SageMaker Real-Time endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25df90f-09be-4e91-812d-cc39c97c433b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Table of Contents\n",
    "- Setup\n",
    "- SageMaker Inference Recommender - Instant Instance Recommendation\n",
    "- SageMaker Inference Recommender - Load Testing and Benchmarking of Real-Time Endpoints\n",
    "    - Setting up variables\n",
    "    - Defining Sample Payload\n",
    "    - Registering Model in the Model Registry\n",
    "- Create an Inference Recommender Default Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b96945-1e1c-46da-a093-1fae8f579f3d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> This notebook requires variable values / data from the <b>rtb_xgboost_Sagemaker_realtime_endpoint_deploy_invoke</b> notebook. Please execute the code in the <b>rtb_xgboost_Sagemaker_realtime_endpoint_deploy_invoke</b> notebook before proceeding.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff6ef27-a280-4742-95cf-d923e75c6bc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "We recommend configuring your Notebook Role to have <b>SageMaker Full Access</b> for testing purposes only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f718f7-c506-4454-bc36-ed2a3ac362a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "import os\n",
    "\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ec0a9-6022-4e93-997f-e5b5d5a798b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Retrieve variables saved in the <b>rtb_xgboost_Sagemaker_realtime_endpoint_deploy_invoke</b> notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608186b-ed9a-4259-bcfc-e9fa49f53d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r image_uri\n",
    "%store -r model_url\n",
    "%store -r model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9b9b6-1a35-4f72-864d-b36ec4a62de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    image_uri\n",
    "    model_url\n",
    "    model_name\n",
    "except NameError:\n",
    "    print(\"*****************************************************************************\")\n",
    "    print(\"[ERROR] PLEASE RE-RUN THE SageMaker Real-Time Inference NOTEBOOK ************\")\n",
    "    print(\"[ERROR] THIS NOTEBOOK WILL NOT RUN PROPERLY. ********************************\")\n",
    "    print(\"*****************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73680c64-f53d-42aa-b656-1b4f5050894d",
   "metadata": {},
   "source": [
    "Print variables saved in the <b>rtb_xgboost_Sagemaker_realtime_endpoint_deploy_invoke</b> notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fd4f1-242c-42ec-99aa-dfd982222415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Image uri : {}'.format(image_uri))\n",
    "print('Model url: {}'.format(model_url))\n",
    "print('Model name: {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c6ad1-b578-4531-b6f7-198cf4a8c359",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SageMaker Inference Recommender - Instant Instance Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5348b83f-9290-4808-b2eb-51353d709b10",
   "metadata": {},
   "source": [
    "SageMaker's Inference Recommender simplifies the process of selecting the optimal instance type for deploying your machine learning model. It performs preliminary analysis on your model and provides a list of the top five recommended instance types on the model details page. You can access the list of prospective instances programmatically through the DescribeModel API, the SageMaker Python SDK, or directly from the SageMaker console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d0731-a265-474d-a22a-e0b6b756d117",
   "metadata": {},
   "source": [
    "The following code block demonstrates how to get instant deployment recommendations from the DescribeModel API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f367755-cb3b-42f0-a5fe-9ef1dcb1d412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "describe_model_response = client.describe_model(ModelName=model_name)\n",
    "deployment_recommendation = describe_model_response.get(\"DeploymentRecommendation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e6dcd-4c6f-48a3-ab58-ebe53b3258d9",
   "metadata": {},
   "source": [
    "We can visualize these recommendations by using the code block below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4aaf91-801e-412c-88d6-91c301e48807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df = pd.DataFrame(\n",
    "    deployment_recommendation.get(\"RealTimeInferenceRecommendations\"),\n",
    "    columns=[\"RecommendationId\", \"InstanceType\", \"Environment\"],\n",
    ")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0d194-f842-4515-a83a-71654fdc601e",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can use the above recommendations as a start for load testing / benchmarking your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a989b-a4a2-4e75-bf5d-62f746037633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recommended_instance_types = df['InstanceType'].values.tolist()\n",
    "print('Recommended instance types : {}'.format(recommended_instance_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a8cb6e-ea2c-4c4a-8f6b-2a622030c0ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "While these initial recommendations serve as a starting point, running additional instance recommendation jobs is advisable for more accurate and comprehensive results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea33954c-c37a-41f5-9b8e-cfe43b1da22e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SageMaker Inference Recommender - Load Testing and Benchmarking Real-Time Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd272dd9-88a9-487c-a2de-63d9ef6a017e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setting up variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620376de-2c3f-4910-a414-b3149b8182a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Inference Recommender uses metadata about your ML model to recommend the best instance types and endpoint configurations for deployment. You can provide as much or as little information as you'd like but the more information you provide, the better your recommendations will be.\n",
    "\n",
    "ML Frameworks: TENSORFLOW, PYTORCH, XGBOOST, SAGEMAKER-SCIKIT-LEARN\n",
    "\n",
    "ML Domains: COMPUTER_VISION, NATURAL_LANGUAGE_PROCESSING, MACHINE_LEARNING\n",
    "\n",
    "Example ML Tasks: CLASSIFICATION, REGRESSION, IMAGE_CLASSIFICATION, OBJECT_DETECTION, SEGMENTATION, MASK_FILL, TEXT_CLASSIFICATION, TEXT_GENERATION, OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a68019-fb3e-4b44-8e4d-fb429f7f81cf",
   "metadata": {},
   "source": [
    "We define variables as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9cce2c-7c2c-4007-9bf2-4439e29489fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml_domain = \"MACHINE_LEARNING\"\n",
    "ml_task = \"CLASSIFICATION\"\n",
    "\n",
    "framework = \"XGBOOST\"\n",
    "framework_version = \"1.0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c2e2e6-b38a-4807-bf30-89e41a3bfe9d",
   "metadata": {},
   "source": [
    "We need to create an archive that contains sample payload that Inference Recommender can send to your SageMaker Endpoints. \n",
    "\n",
    "Here we are only adding a single CSV file with one example. In your own use case(s), it's recommended to add a variety of samples that is representative of your payloads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add2f5d4-1c81-46ee-9ba1-6beabe5b0929",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Defining Sample Payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e61a3f-48e2-41bc-ab26-4238645f4474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_input_configuration = b\"2,0,0.0,7.0,3.0,20.0,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a2ad3-1e55-4436-9de9-7a57104c2c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload_location = \"./sample-payload/\"\n",
    "\n",
    "if not os.path.exists(payload_location):\n",
    "    os.makedirs(payload_location)\n",
    "    print(\"Directory \", payload_location, \" Created \")\n",
    "else:\n",
    "    print(\"Directory \", payload_location, \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc21c0-629d-41bb-a2ee-d36c265503eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload_archive_location = payload_location + \"xgb_payload.tar.gz\"\n",
    "payload_file_location = payload_location + \"sample.csv\"\n",
    "\n",
    "with open(payload_file_location,'wb') as file:\n",
    "        file.write(data_input_configuration)\n",
    "        file.write(b\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465173f6-d34e-4651-974d-e8a210114958",
   "metadata": {},
   "source": [
    "Next, we create a tarball with sample payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc1dd0-8283-4f93-97c2-304f0e34edfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -cvzf {payload_archive_location} {payload_file_location}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28dd0f-15eb-4dd5-bf0c-538335999d8c",
   "metadata": {},
   "source": [
    "We upload the packaged payload examples (payload.tar.gz) that was created above to S3. The S3 location will be used as input to our Inference Recommender job later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc22ba7-d8cb-448c-9b5e-240e78a6fb50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_payload_url = sagemaker_session.upload_data(\n",
    "    path=payload_archive_location, key_prefix=\"xgb_payload\"\n",
    ")\n",
    "\n",
    "print(\"Sample Payload S3 URL: \" + sample_payload_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc1170-4d0f-43ba-8016-9989e9301c59",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Registering Model in the Model Registry\n",
    "\n",
    "In order to use Inference Recommender, you must have a versioned model in SageMaker Model Registry. To register a model in the Model Registry, you must have a model artifact packaged in a tarball and an inference container image. Registering a model includes the following steps:\n",
    "\n",
    "- <b>Create Model Group:</b> This is a one-time task per machine learning use case. A Model Group contains one or more versions of your packaged model.\n",
    "- <b>Register Model Version/Package:</b> This task is performed for each new packaged model version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1047a45-deb3-4754-9a5b-a7f4720f4c22",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the following code block we create a model group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9ba0a-7f7b-48ee-bcaa-3b8a3d5e5fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model_package_group_name = \"xgb-bid-filtering-rtb-model-package-group-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_package_group_input_dict = {\n",
    " \"ModelPackageGroupName\" : model_package_group_name,\n",
    " \"ModelPackageGroupDescription\" : \"RTB traffic filtering model group\"\n",
    "}\n",
    "\n",
    "create_model_package_group_response = client.create_model_package_group(**model_package_group_input_dict)\n",
    "print('ModelPackageGroup Arn : {}'.format(create_model_package_group_response['ModelPackageGroupArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd8915-e89f-4072-b72b-a00c4c29aec3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Defining Model Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e5a91-04dd-4807-a6fd-60321c2966df",
   "metadata": {
    "tags": []
   },
   "source": [
    "For the inference container image we use the URI of the deep learning container (DLC) provided by Amazon (defined in the previous notebook). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1955e1-3987-41fd-98c6-0d12db066676",
   "metadata": {
    "tags": []
   },
   "source": [
    "You'll register your pretrained model that was packaged in the prior steps as a new version in SageMaker Model Registry. First, you'll configure the model package/version identifying which model package group this new model should be registered within as well as identify the initial approval status. You'll also identify the domain and task for your model. These values were set earlier in the notebook where ml_domain = 'MACHINE_LEARNING' and ml_task = 'CLASSIFICATION'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad9fb9e-460c-489b-b3a2-a2b151fa37f5",
   "metadata": {},
   "source": [
    "> Note: ModelApprovalStatus is a configuration parameter that can be used in conjunction with SageMaker Projects to trigger automated deployment pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5c80c-1b5f-466c-939f-91e45035db38",
   "metadata": {
    "tags": []
   },
   "source": [
    "If you specify a set of instance types below (i.e. non-empty list), then Inference Recommender will only support recommendations within the set of instances. \n",
    "\n",
    "Here, as an example, we specified ths list of initially recommended instance types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df8400-b6ee-47c5-a779-5c64380dac47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify MIME type for the model (type of data model will accept and/or return)\n",
    "mime_types = [\"text/csv\"]\n",
    "\n",
    "# Specify the model inference specification\n",
    "modelpackage_inference_specification =  {\n",
    "    \"InferenceSpecification\": {\n",
    "      \"Containers\": [\n",
    "         {\n",
    "            \"Image\": image_uri,\n",
    "            \"ModelDataUrl\": model_url,\n",
    "         }\n",
    "      ],\n",
    "      \"SupportedContentTypes\": mime_types,\n",
    "      \"SupportedResponseMIMETypes\": mime_types,\n",
    "      #\"SupportedRealtimeInferenceInstanceTypes\": recommended_instance_types\n",
    "   }\n",
    " }\n",
    "\n",
    "create_model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\" : model_package_group_name,\n",
    "    \"ModelPackageDescription\" : \"RTB traffic filtering model\",\n",
    "    \"Domain\": ml_domain.upper(),\n",
    "    \"Task\": ml_task.upper(),\n",
    "    \"SamplePayloadUrl\": sample_payload_url,    \n",
    "    \"ModelApprovalStatus\" : \"PendingManualApproval\"\n",
    "}\n",
    "create_model_package_input_dict.update(modelpackage_inference_specification)\n",
    "\n",
    "create_model_package_response = client.create_model_package(**create_model_package_input_dict)\n",
    "model_package_arn = create_model_package_response[\"ModelPackageArn\"]\n",
    "print('ModelPackage Version ARN : {}'.format(model_package_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca8ae77-16ff-4781-91ff-b3e21d28c132",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create an Inference Recommender Default Job\n",
    "\n",
    "Now with your model in Model Registry, you can start a 'Default' job to get instance recommendations. This only requires your ModelPackageVersionArn and comes back with recommendations within 15-20 minutes.\n",
    "\n",
    "The output is a list of instance type recommendations with associated environment variables, cost, throughput and latency metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce962d-95a8-44b9-9970-520b491babb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "# Create a low-level SageMaker service client.\n",
    "aws_region = region\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=aws_region) \n",
    "\n",
    "# Provide your model package ARN that was created when you registered your model with Model Registry \n",
    "model_package_arn = model_package_arn\n",
    "\n",
    "# Provide a unique job name for SageMaker Inference Recommender job\n",
    "job_name = \"xgb-bid-filtering-real-time-benchmark-test\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# Inference Recommender job type. Set to Default to get an initial recommendation\n",
    "job_type = 'Default'\n",
    "\n",
    "# Provide an IAM Role that gives SageMaker Inference Recommender permission to \n",
    "# access AWS services\n",
    "role_arn = role\n",
    "                                    \n",
    "# Provide endpoint name for your endpoint that want to benchmark in Inference Recommender\n",
    "endpoint_name = 'xgb-bid-filtering-realtime-ep2024-03-04-21-19-41'\n",
    "\n",
    "sagemaker_client.create_inference_recommendations_job(\n",
    "    JobName = job_name,\n",
    "    JobType = job_type,\n",
    "    RoleArn = role_arn,\n",
    "    InputConfig = {\n",
    "        'ModelPackageVersionArn': model_package_arn,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b48d2-786f-4969-9686-ddb27b40d5fb",
   "metadata": {},
   "source": [
    "The following code will wait for the job to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aeab03-b33f-46e6-943f-40c3c40ddee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "\n",
    "finished = False\n",
    "while not finished:\n",
    "    inference_recommender_job = client.describe_inference_recommendations_job(JobName=job_name)\n",
    "    if inference_recommender_job[\"Status\"] in [\"COMPLETED\", \"STOPPED\", \"FAILED\"]:\n",
    "        finished = True\n",
    "    else:\n",
    "        print(\"In progress\")\n",
    "        time.sleep(60)\n",
    "\n",
    "if inference_recommender_job[\"Status\"] == \"FAILED\":\n",
    "    print(\"Inference recommender job failed \")\n",
    "    print(\"Failed Reason: {}\".inference_recommender_job[\"FailedReason\"])\n",
    "else:\n",
    "    print(\"Inference recommender job completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d72bad1-2673-4e5e-bcb5-08d741c62c98",
   "metadata": {},
   "source": [
    "To see the list of subtasks for an Inference Recommender job, we provide the JobName to the ListInferenceRecommendationsJobSteps API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd37d45-e65e-433d-bf28-7353ad91e1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    {**x[\"EndpointConfiguration\"], **x[\"ModelConfiguration\"], **x[\"Metrics\"]}\n",
    "    for x in inference_recommender_job[\"InferenceRecommendations\"]\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "dropFilter = df.filter([\"VariantName\"])\n",
    "df.drop(dropFilter, inplace=True, axis=1)\n",
    "pd.set_option(\"max_colwidth\", 300)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62938931-92a2-45c4-b8d1-adfaf3dd93a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Each inference recommendation includes:\n",
    "- `EndpointName` - Name of endpoint used by Inference Recommender to run the job\n",
    "- `ServerlessConfig` - Configuraion/tests for three serverless endpoints of various Memory configurations\n",
    "- `EnvironmentParameters` - Suggested tuned parameters for better performance. To take advantage of these optimizations you can include these parameters as Environment variables when creating your endpoints \n",
    "\n",
    "\n",
    "Output also includes performance and cost metrics such as \n",
    "- `CostPerHour` - Cost of running the endpoint for an hour (US Dollars)\n",
    "- `CostPerInference` - Cost per one inference request (US Dollars)\n",
    "- `MaxInvocations` - The number of invocations sent to endpoint (per minute)\n",
    "- `ModelLatency` - Model latency registered during the stress test (in milliseconds)\n",
    "- `InstanceType`- Instance type used for the test\n",
    "- `InitialInstanceCount` - The number of instances initialized for each test. \n",
    "- `CPU Utilization` - The expected CPU utilization at maximum invocations per minute for the endpoint instance.\n",
    "\n",
    "You can read more about interpreting the results here: https://docs.aws.amazon.com/sagemaker/latest/dg/inference-recommender-interpret-results.html\n",
    "\n",
    "These metrics can help you narrow down to a specific endpoint configuration that suits your use case\n",
    "\n",
    "Example:\n",
    "\n",
    "If your motivation is overall price-performance with an emphasis on throughput, then you should focus on `CostPerInference` metrics.\n",
    "\n",
    "If your motivation is a balance between latency and throughput, then you should focus on `ModelLatency` / `MaxInvocations` metrics."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
